{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_ML import  get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed OHLCV at frequency 1D\n",
      "reading cache of TXF in 1D OHLCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyyen/miniconda3/envs/stock_path_tracker/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:980: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  result = concat(values, axis=self.axis, keys=keys)\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "DIRECTION = 'is_turnpt_upward'\n",
    "CACHE = True\n",
    "ADD_DIFF = 0\n",
    "PCT_TRAIN = 0.75\n",
    "y, X, idx, num_train = get_data(N, DIRECTION, CACHE, ADD_DIFF, PCT_TRAIN)\n",
    "num_test = len(y) - num_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# long-only strategy\n",
    "- time point: \n",
    "    - t0 收盤時，得到 s0 訊號\n",
    "    - t+1 開盤進場（目前簡化先用 t0 收盤價代替）\n",
    "- predict TP_upward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Logistics regression as baseline\n",
    "- reference: https://towardsdatascience.com/weighted-logistic-regression-for-imbalanced-dataset-9a5cd88e68b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=1-PCT_TRAIN, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "default Loigistic Regression model without tuning any hyperparameters\n",
    "------------------------------------------------------------------------------------\n",
    "Accuracy Score: 0.945031712473573\n",
    "\n",
    "Confusion Matrix:\n",
    "        Negative\tPositve\n",
    "False\t446         5\n",
    "True\t21\t        1\n",
    "\n",
    "Area Under Curve: 0.5171840354767183\n",
    "Recall score: 0.045454545454545456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 ms, sys: 14.9 ms, total: 286 ms\n",
      "Wall time: 39.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.03, 1: 1}, max_iter=1000, random_state=13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w = {0: 0.03, 1: 1}\n",
    "model = LogisticRegression(random_state=13, max_iter=10**3, class_weight=w)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5983086680761099\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>262</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Negative  Positve\n",
       "False       262      189\n",
       "True          1       21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve: 0.7677383592017739\n",
      "Recall score: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, y_pred), index=['False', 'True'], columns=['Negative', 'Positve']))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurency_train = model.score(X_train, y_train, sample_weight=y_train*100+1)\n",
    "accurency_test = model.score(X_test, y_test, sample_weight=y_test*100+1)\n",
    "assert (accurency_test - accurency_train) < 0.1, 'accurency differene between training and testing is larger than 10% '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([ 0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
      "        6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5, 11. ,\n",
      "       11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. , 16.5,\n",
      "       17. , 17.5, 18. , 18.5, 19. , 19.5]),\n",
      " 'class_weight': [{0: 0.025, 1: 1},\n",
      "                  {0: 0.026, 1: 1},\n",
      "                  {0: 0.027, 1: 1},\n",
      "                  {0: 0.028, 1: 1},\n",
      "                  {0: 0.029, 1: 1},\n",
      "                  {0: 0.03, 1: 1},\n",
      "                  {0: 0.031, 1: 1},\n",
      "                  {0: 0.032, 1: 1},\n",
      "                  {0: 0.033, 1: 1},\n",
      "                  {0: 0.034, 1: 1}],\n",
      " 'fit_intercept': [True, False]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=100,\n",
       "             estimator=LogisticRegression(max_iter=1000, random_state=13),\n",
       "             param_grid={'C': array([ 0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
       "        6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5, 11. ,\n",
       "       11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. , 16.5,\n",
       "       17. , 17.5, 18. , 18.5, 19. , 19.5]),\n",
       "                         'class_weight': [{0: 0.025, 1: 1}, {0: 0.026, 1: 1},\n",
       "                                          {0: 0.027, 1: 1}, {0: 0.028, 1: 1},\n",
       "                                          {0: 0.029, 1: 1}, {0: 0.03, 1: 1},\n",
       "                                          {0: 0.031, 1: 1}, {0: 0.032, 1: 1},\n",
       "                                          {0: 0.033, 1: 1}, {0: 0.034, 1: 1}],\n",
       "                         'fit_intercept': [True, False]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.96 with param: {'C': 0.5, 'class_weight': {0: 0.025, 1: 1}, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    w = [\n",
    "        {0: i/1000, 1: 1}\n",
    "        for i in range(25, 35)\n",
    "    ]\n",
    "    crange = np.arange(0.5, 20.0, 0.5)\n",
    "    hyperparam_grid = {\n",
    "        \"class_weight\": w , \n",
    "    #     \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": crange,\n",
    "        \"fit_intercept\": [True, False],\n",
    "    }\n",
    "    pprint(hyperparam_grid)\n",
    "\n",
    "    lg3 = LogisticRegression(random_state=13, max_iter=10**3)\n",
    "    # define evaluation procedure\n",
    "    grid = GridSearchCV(lg3,hyperparam_grid, scoring=\"recall\", cv=100, refit=True)\n",
    "    grid.fit(X_scaled, y)\n",
    "\n",
    "    print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
